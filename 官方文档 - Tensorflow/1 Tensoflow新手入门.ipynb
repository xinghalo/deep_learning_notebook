{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本篇介绍Keras的使用：\n",
    "- 构建图片分类网络模型\n",
    "- 训练神经网络\n",
    "- 评估模型准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载MNIST数据集，并进行数据的预处理。把0-255的灰度值转为0-1.0的浮点数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建Keras的Sequential模型，并设计内部的网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于每个样例，模型会计算对应的logits值, 模型输出了预测后的10个值.\n",
    "\n",
    "这里的logits可以理解为模型输出的原始值，进入softmax之前的值：\n",
    "\n",
    "[如何理解深度学习源码里经常出现的logits](https://www.zhihu.com/question/60751553)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[-0.8408619 , -0.19510293, -0.5035249 , -0.269258  ,  0.12426727,\n",
       "        -0.1912828 ,  0.17483345,  0.37996706, -0.25280207, -0.69904244]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(x_train[:1])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 .numpy() 方法可以直接获得对应的numpy数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8408619 , -0.19510293, -0.5035249 , -0.269258  ,  0.12426727,\n",
       "        -0.1912828 ,  0.17483345,  0.37996706, -0.25280207, -0.69904244]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当前输出的是原始数据值，可以通过softmax进行空间归一化(一般都会把Dense层作为最后一层，然后使用softmax进行归一化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0507003 , 0.09670747, 0.07104182, 0.08979557, 0.1330947 ,\n",
       "        0.09707762, 0.13999785, 0.17187384, 0.09128547, 0.05842543]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SparseCategoricalCrossentropy提供分类交叉熵的计算，可以用于多分类问题中的损失值计算。\n",
    "\n",
    "- 当预测正确时，损失值为0\n",
    "- 当预测错误时，损失值为-log(1/10) ≈ 2.3\n",
    "\n",
    "问题1：from_logits的作用？\n",
    "- from_logits=True表示模型输出的是原始值\n",
    "- from_logits=False表示模型输出的是softmax值\n",
    "\n",
    "问题2：SparseCategoricalCrossentropy与CategoricalCrossentropy的区别？\n",
    "- 对预测样本值（label或y）的要求不同：SparseCategoricalCrossentropy中的y是原始数值；CategoricalCrossentropy是one-hot编码值.\n",
    "- 在SparseCategoricalCrossentropy中label的值对应的是predictions中概率最大的下标索引。比如1 对应的是 [0.2, 0.6, 0.2]；2对应的是[0.2, 0.2, 0.6]\n",
    "\n",
    "问题3：BinaryCrossentropy的计算原理\n",
    "\n",
    "BinaryCrossentropy用于针对二分类求损失值，一般损失值可以使用y-predict配合平方或者绝对值来计算，但是二分类问题就没办法用这种方式计算了。此时可以考虑使用交叉熵，计算公式为：`-(t*tf.log(o+eps) + (1.0-t)*tf.log(1.0-o+eps))`，其中t代表目标值，o代表输出值。当t和o相同时，代表预测正确，此时两项均为0，很巧妙吧！当t为1，o为0时，前面为log(0+eps)，由于log(0)是无穷小，因此需要加入一个eps值保证得到一个极小值输出，由于前面带有负号，因此输出值为正的最大值，也就代表此时损失值非常大。同理当t为0，o为1时，前面为0，后面又是一个正的很大的数。\n",
    "\n",
    "问题4：CategoricalCrossentropy的计算原理\n",
    "\n",
    "![](https://pic4.zhimg.com/80/v2-a925abffa7feb0dbd71be9e3d9e41990_1440w.jpg?source=1940ef5c)\n",
    "\n",
    "计算公式如上图所示，可以通俗的理解成，每个多分类问题被看做每个目标的二分类问题。比如手写体识别的十分类问题，会根据目标值划分成对应的二分类，假设目标是3，那么对应的二分类问题就是 是3、不是3。从而基于对应的softmax位置上的概率就是目标值的概率，在根据-log(p)来求解损失值就可以了。此时仅当p=1时，损失值最小且等于0；当p在0~1之间时，损失值会从负的无穷大到0。从而就评估出了对应的多分类的损失值了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n",
      "[[-0.8408619  -0.19510293 -0.5035249  -0.269258    0.12426727 -0.1912828\n",
      "   0.17483345  0.37996706 -0.25280207 -0.69904244]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.3322444"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "print(y_train[:1])\n",
    "print(predictions.numpy())\n",
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2926 - accuracy: 0.9146\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1435 - accuracy: 0.9575\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1076 - accuracy: 0.9675\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0890 - accuracy: 0.9731\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0752 - accuracy: 0.9766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6a4b3b56a0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用model.evaluate方法评估模型的准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0756 - accuracy: 0.9759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07559826225042343, 0.9758999943733215]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图像分类模型的准确率大概98%。\n",
    "\n",
    "如果希望模型返回softxmax值，可以直接针对model进行包装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.7004161e-08, 1.4099356e-07, 9.8216715e-06, 1.2858350e-04,\n",
       "        1.3957984e-09, 1.2577340e-06, 9.7083739e-12, 9.9985301e-01,\n",
       "        1.4599189e-07, 6.8429790e-06],\n",
       "       [4.1756949e-09, 6.7698835e-05, 9.9989355e-01, 7.8099019e-06,\n",
       "        3.4236723e-14, 3.7844652e-07, 9.0134915e-07, 9.1847377e-11,\n",
       "        2.9549239e-05, 3.5813357e-12],\n",
       "       [6.2518086e-07, 9.9894673e-01, 1.7064613e-04, 2.9825354e-05,\n",
       "        3.6638401e-05, 1.3653870e-05, 7.5012329e-05, 5.7355949e-04,\n",
       "        1.4940834e-04, 3.8304020e-06],\n",
       "       [9.9952269e-01, 6.6020093e-08, 2.9928182e-04, 4.6554760e-06,\n",
       "        4.2029026e-07, 7.5383873e-06, 1.1877981e-04, 7.0978863e-06,\n",
       "        3.0132203e-06, 3.6464786e-05],\n",
       "       [2.1729713e-06, 1.5488399e-09, 5.5017819e-07, 1.1670326e-07,\n",
       "        9.9543977e-01, 1.1058410e-06, 6.2252218e-07, 8.8674817e-05,\n",
       "        8.2469768e-07, 4.4661383e-03]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "p_model(x_test[:5]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
